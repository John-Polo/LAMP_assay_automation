{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "readDNGsavePNG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwNpd+Ra+zMkrg7HZ8cJjT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ncsu-landscape-dynamics/LAMP_assay_automation/blob/main/readDNGsavePNG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riua8jQHxii5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7495004a-8f43-435a-d316-299705417832"
      },
      "source": [
        "# Prelimns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "!pip install rawpy # <- Google colab format\n",
        "import rawpy\n",
        "#\n",
        "#\n",
        "# Not necessary currently. \n",
        "#import cv2\n",
        "#import imageio\n",
        "#import scipy.misc\n",
        "#import skimage.filters\n",
        "#import skimage.metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rawpy\n",
            "  Downloading rawpy-0.16.0-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rawpy) (1.19.5)\n",
            "Installing collected packages: rawpy\n",
            "Successfully installed rawpy-0.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2L8vCQJxwGu",
        "outputId": "28a7c936-b52c-4092-ce6b-96fa1d41fa58"
      },
      "source": [
        "# Likely not needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgZH4QqLVdrm"
      },
      "source": [
        "# This may be removed. Considering whether or not to read raw image and convert\n",
        "# over to tensor in this one script. Used in last block.\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import convert_image_dtype\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLlIp5bzMcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c581fe8f-d30b-4464-a494-d13d25a0cf25"
      },
      "source": [
        "# Where are the new RAW images that will need to be changed before modeling?\n",
        "img_dir = input(\"Please provide a directory path that has the images awaiting\\\n",
        " analysis.\")\n",
        "\n",
        "try:\n",
        "    os.path.exists(img_dir) == False\n",
        "except:\n",
        "    sys.exit(\"The path provided does not exist. Do you need to provide a\\\n",
        "    leading '/' (on Windows, you need to provide 'C:\\' instead).\")\n",
        "\n",
        "os.chdir(img_dir)\n",
        "print(\"The directory provided was {}.\".format(os.getcwd()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide a directory path that has the images awaiting analysis./content/drive/MyDrive/APHIS Farm Bill (2020Milestones)/Protocols/For John/images/New set for John/input\n",
            "The directory provided was /content/drive/.shortcut-targets-by-id/1-5I4VO21o4cSUAm5QhufEXgNX_wbZVfg/APHIS Farm Bill (2020Milestones)/Protocols/For John/images/New set for John/input.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVSXqcVC5K7Y"
      },
      "source": [
        "# Names and locations of images for reading.\n",
        "rawimgs = sorted(os.listdir())\n",
        "rawimgs_dir = list()\n",
        "\n",
        "for i in range(len(rawimgs)):\n",
        "    rawimgs_dir.append(os.path.join(\"/content/drive/MyDrive/APHIS Farm Bill (2020Milestones)/Protocols/For John/images/New set for John/input\" , rawimgs[i]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92xfUAssUq9t",
        "outputId": "433ec853-363e-444f-bcbd-118626f94149"
      },
      "source": [
        "# Read RAW images, postprocess, and check orientation.\n",
        "raw_in_list = list()\n",
        "post_im_list = list()\n",
        "\n",
        "for r in range(len(rawimgs_dir)):\n",
        "    raw_in_list.append(rawpy.imread(rawimgs_dir[r]))\n",
        "    post_im_list.append(raw_in_list[r].postprocess(use_camera_wb=True))\n",
        "    if post_im_list[r].shape[0] < post_im_list[r].shape[1]:\n",
        "        post_im_list[r] = np.rot90(post_im_list[r], 3)\n",
        "        print(\"Note: horizontal images detected. Inspect orientation.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n",
            "Note: horizontal images detected. Inspect orientation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQkN15MhzybU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f426319-6fa5-44be-9a33-76fc452d3fa5"
      },
      "source": [
        "# Save images as PNG full-size. \n",
        "dir_save = input(\"Please provide a directory path for saving images.\")\n",
        "\n",
        "try:\n",
        "    os.path.exists(dir_save) == False\n",
        "except:\n",
        "    sys.exit(\"The path provided does not exist. Do you need to provide a\\\n",
        "    leading '/' (on Windows, you need to provide 'C:\\' instead).\")\n",
        "\n",
        "newnamelis = list()\n",
        "save_names_path = list()\n",
        "\n",
        "for i in range(len(rawimgs)):\n",
        "    newnamelis.append(rawimgs[i].replace(\"dng\",\"png\"))\n",
        "    save_names_path.append(os.path.join(\"/content/drive/MyDrive/APHIS Farm Bill (2020Milestones)/Protocols/For John/images/New set for John/\", dir_save, newnamelis[i]))\n",
        "    post_im_list[i] = Image.fromarray(post_im_list[i])\n",
        "    post_im_list[i].save(save_names_path[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide a directory path that has the images awaiting analysis./content/drive/MyDrive/APHIS Farm Bill (2020Milestones)/Protocols/For John/images/New set for John/test_save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eVuqJ8RhyIq"
      },
      "source": [
        "# The if statement here is dodgy. An array or tensor has shape AND size. Only\n",
        "# the PIL Images have only shape. Tried using type(img), but that's only for\n",
        "# base types, like \"str\" or \"int\".\n",
        "def centercrop(img, newsize):\n",
        "    if hasattr(img, \"shape\"):\n",
        "        height, width = img.shape[:2]   # Get dimensions\n",
        "        img = Image.fromarray(img)\n",
        "        print(\"img is tensor or np.array. widt = {}, height = {}\".format(width,height))\n",
        "    else:\n",
        "        width, height = img.size   # Get dimensions\n",
        "        print(\"img is PIL. widt = {}, height = {}\".format(width,height))\n",
        "    left = int((width - int(newsize))/2)\n",
        "    top = int((height - int(newsize))/2)\n",
        "    bottom = int(height - top)\n",
        "    right = int(width - left)\n",
        "    # Crop the center of the image\n",
        "    ccrp = img.crop((left, top, right, bottom))\n",
        "    return ccrp "
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMIy4EeGoZ2S",
        "outputId": "23a0a15a-0498-4179-cc3e-424d3fb8b134"
      },
      "source": [
        "# Crop images. 1600 x 1600\n",
        "cencrop_lis = list()\n",
        "\n",
        "for i in range(len(post_im_list)):\n",
        "    cencrop_lis.append(centercrop(post_im_list[i], 1600))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n",
            "img is tensor or np.array. widt = 2988, height = 5312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C589CZGL98lA"
      },
      "source": [
        "# For saving the cropped images.\n",
        "newnamelis = list()\n",
        "png_names_path = list()\n",
        "\n",
        "for i in range(len(rawimgs)):\n",
        "    newnamelis.append(rawimgs[i].replace(\"dng\",\"png\"))\n",
        "    png_names_path.append(os.path.join(\"/content/drive/MyDrive/APHIS Farm Bill (2020Milestones)/Protocols/For John/images/New set for John/centercroptest/\", newnamelis[i]))\n",
        "    cencrop_lis[i].save(png_names_path[i])"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dJOKxZbBZXM"
      },
      "source": [
        "# Write out a bunch of plt. statements because I don't know how to call plt in a loop.\n",
        "for i in range(len(post_im_list)):\n",
        "    colus = int(len(post_im_list)/6)\n",
        "    print(\"plt.subplot(6,{},{})\".format(colus,i+1))\n",
        "    print(\"plt.imshow(post_im_list[{}])\".format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD2qd_aJPYHg"
      },
      "source": [
        "# Optional plotting here.\n",
        "plt.figure(figsize=(40,20))\n",
        "\n",
        "plt.subplot(..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KC5MhXYWAXd"
      },
      "source": [
        "# Unstested.\n",
        "# Read raw and convert to tensor. \n",
        "first_tensor_list = list()\n",
        "model_tensor_list = list()\n",
        "\n",
        "for i in range(len(cencrop_lis)):\n",
        "    tensor_list.append(torch.tensor(cencrop_lis[i]))\n",
        "    tensor_list[i] = tensor_list[i].to(device)\n",
        "    model_tensor_list[i].append(convert_image_dtype(first_tensor_list[i], dtype=torch.float))"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}